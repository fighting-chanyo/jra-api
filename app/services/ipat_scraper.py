import os
import hashlib
import json
from fastapi import HTTPException
from playwright.sync_api import sync_playwright
from app.schemas import IpatAuth
from app.services.parsers import parse_jra_csv
from app.services.supabase_client import get_supabase_client
from app.constants import RACE_COURSE_MAP

def _map_ticket_to_db_format(ticket_data, user_id):
    """ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’DBã®ticketsãƒ†ãƒ¼ãƒ–ãƒ«ã®å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    raw = ticket_data["raw"]
    parsed = ticket_data["parsed"]

    # race_id (YYYYMMDDPPRR) ã®ç”Ÿæˆ
    place_code = RACE_COURSE_MAP.get(raw["race_place"], "00")
    race_no = raw["race_number_str"].zfill(2)
    race_id = f"{raw['race_date_str']}{place_code}{race_no}"

    # receipt_unique_id (ãƒãƒƒã‚·ãƒ¥åŒ–) ã®ç”Ÿæˆ
    content_str = json.dumps(parsed["content"], sort_keys=True)
    # ã€ä¿®æ­£ã€‘æ—¥ä»˜ã‚’å«ã‚ã¦ã€æ—¥ã‚’ã¾ãŸã„ã§ã‚‚ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹
    unique_str = f"{raw['race_date_str']}-{raw['receipt_no']}-{raw['line_no']}-{content_str}"
    receipt_unique_id = hashlib.md5(unique_str.encode()).hexdigest()

    # total_points ã®è¨ˆç®— (0é™¤ç®—ã‚’å›é¿)
    total_points = 0
    if parsed["amount_per_point"] > 0:
        total_points = parsed["total_cost"] // parsed["amount_per_point"]

    # DBã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ§‹æˆ
    return {
        "user_id": user_id,
        "race_id": race_id,
        "bet_type": parsed["bet_type"],
        "buy_type": parsed["buy_type"],
        "content": parsed["content"],
        "amount_per_point": parsed["amount_per_point"],
        "total_points": total_points,
        "total_cost": parsed["total_cost"],
        "payout": parsed["payout"],
        "status": parsed["status"],
        "source": "IPAT_SYNC",
        "receipt_unique_id": receipt_unique_id
    }


def sync_and_save_past_history(log_id: str, user_id: str, creds: IpatAuth):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼"""
    supabase = get_supabase_client()
    print(f"BACKGROUND JOB STARTED for log_id: {log_id}")

    try:
        # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ãƒ‘ãƒ¼ã‚¹
        parsed_tickets = _scrape_past_history_csv(creds)
        if not parsed_tickets:
            # ãƒã‚±ãƒƒãƒˆãŒ0ä»¶ã§ã‚‚æ­£å¸¸çµ‚äº†ã¨ã™ã‚‹
            supabase.table("sync_logs").update({
                "status": "COMPLETED",
                "message": "Synced 0 tickets. No betting data found."
            }).eq("id", log_id).execute()
            print(f"âœ… BACKGROUND JOB COMPLETED: No tickets found for log_id: {log_id}")
            return

        # 2. DBå½¢å¼ã¸ã®å¤‰æ›
        db_records = [_map_ticket_to_db_format(t, user_id) for t in parsed_tickets]
        
        # 3. DBã¸ä¿å­˜ (Upsert)
        print(f"   Upserting {len(db_records)} records to 'tickets' table...")
        supabase.table("tickets").upsert(db_records, on_conflict="receipt_unique_id").execute()

        # 4. ãƒ­ã‚°ã‚’æˆåŠŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«æ›´æ–°
        supabase.table("sync_logs").update({
            "status": "COMPLETED",
            "message": f"Synced {len(db_records)} tickets successfully."
        }).eq("id", log_id).execute()

        print(f"âœ… BACKGROUND JOB COMPLETED for log_id: {log_id}")

    except Exception as e:
        # 5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: ãƒ­ã‚°ã‚’ã‚¨ãƒ©ãƒ¼ã«æ›´æ–°
        error_message = f"An error occurred: {str(e)}"
        print(f"âŒ BACKGROUND JOB FAILED for log_id: {log_id}. Error: {error_message}")
        try:
            supabase.table("sync_logs").update({
                "status": "ERROR",
                "message": error_message
            }).eq("id", log_id).execute()
        except Exception as db_error:
            print(f"  Additionally failed to update sync_logs: {db_error}")

def _scrape_past_history_csv(creds: IpatAuth):
    """Playwrightã«ã‚ˆã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨CSVãƒ‘ãƒ¼ã‚¹å‡¦ç†ã‚’æ‹…ã† (æ—§sync_past_history)"""
    print("ğŸš€ Accessing JRA Vote Inquiry (PC/CSV Mode)...")
    all_parsed_data = []
    
    with sync_playwright() as p:
        is_headless = os.getenv("HEADLESS", "true").lower() != "false"
        browser = p.chromium.launch(headless=is_headless)
        context = browser.new_context(accept_downloads=True)
        context.route("**/*.{png,jpg,jpeg,gif,webp,svg,woff,woff2,css}", lambda route: route.abort())
        page = context.new_page()
        page.on("dialog", lambda dialog: dialog.accept())
        
        print("ğŸ‘‰ Logging in to PC site...")
        page.goto("https://www.nvinq.jra.go.jp/jra/")
        page.wait_for_selector("#UID")
        page.locator("#UID").fill(creds.subscriber_number)
        page.locator("#PWD").fill(creds.password)
        page.locator("#PARS").fill(creds.pars_number)
        page.locator("input[type='submit'][value='ãƒ­ã‚°ã‚¤ãƒ³']").click()
        page.wait_for_load_state("networkidle")

        print("ğŸ‘‰ Navigating to Vote Inquiry (JRAWeb320)...")
        menu_btn = page.locator("tr:has-text('æŠ•ç¥¨å†…å®¹ç…§ä¼š') input[type='submit']").first
        if not menu_btn.is_visible():
            menu_btn = page.locator("input[value='é¸æŠ']").first
        if not menu_btn.is_visible():
            with open("debug_login_failed.html", "w", encoding="utf-8") as f: f.write(page.content())
            raise Exception("Login Failed or Menu Changed. See debug_login_failed.html")
        menu_btn.click()
        page.wait_for_load_state("networkidle")

        print("ğŸ‘‰ Navigating to Receipt Number List (JRAWeb020)...")
        accept_link = page.locator("a.toAcceptnoNum")
        if accept_link.is_visible():
            accept_link.click()
        else:
            page.evaluate("document.forms['Go020'].submit()")
        
        # --- ã“ã“ã‹ã‚‰ä¿®æ­£ ---
        # ãƒšãƒ¼ã‚¸é·ç§»ã‚’å¾…æ©Ÿã—ã€ã¾ãšã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
        try:
            # ã€Œæ—¥ä»˜é¸æŠã€ãƒšãƒ¼ã‚¸ã€ã¾ãŸã¯ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œã€ãƒšãƒ¼ã‚¸ã®ã©ã¡ã‚‰ã‹ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
            page.wait_for_load_state("domcontentloaded", timeout=15000)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œç”»é¢ã®ç‰¹æœ‰ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã§åˆ¤å®š
            if page.locator("text=ãƒ­ã‚°ã‚¤ãƒ³ãŒç„¡åŠ¹ã¨ãªã£ãŸã‹").is_visible():
                raise Exception("Session timed out or became invalid. Please try again.")

        except Exception as e:
            # is_visible()ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„ã€ç‹¬è‡ªã«raiseã—ãŸä¾‹å¤–ã‚’æ•æ‰
            error_message = str(e) if str(e) else "Failed to determine page state after navigation."
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æœ€çµ‚çš„ãªç”»é¢ã‚’ä¿å­˜
            with open("debug_navigation_error.html", "w", encoding="utf-8") as f:
                f.write(page.content())
            raise Exception(error_message)

        print("ğŸ‘‰ Checking Date List...")
        date_buttons = page.locator("input[value='é¸æŠ']")
        date_count = date_buttons.count()
        print(f"ğŸ‘€ Found {date_count} date buttons.")

        if date_count == 0:
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã¯é€šéã—ãŸãŒãƒœã‚¿ãƒ³ãŒãªã„å ´åˆ
            print("âš ï¸ No dates found. Maybe no betting history.")
            return []
        # --- ã“ã“ã¾ã§ä¿®æ­£ ---

        for i in range(date_count):
            page.locator("input[value='é¸æŠ']").nth(i).click()
            page.wait_for_load_state("networkidle")
            csv_btn = page.locator("form[action*='JRACSVDownload'] input[name='normal']")
            if csv_btn.is_visible():
                with page.expect_download() as download_info:
                    csv_btn.click()
                download = download_info.value
                csv_path = f"temp_history_{i}.csv"
                download.save_as(csv_path)
                parsed = parse_jra_csv(csv_path)
                all_parsed_data.extend(parsed)
                os.remove(csv_path)
            
            back_btn = page.locator("input[value*='æ—¥ä»˜é¸æŠ']").first
            if back_btn.is_visible():
                back_btn.click()
            else:
                page.go_back()
            page.wait_for_load_state("networkidle")

        browser.close()

    return all_parsed_data