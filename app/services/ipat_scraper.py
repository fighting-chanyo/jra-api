import os
import hashlib
import json
from fastapi import HTTPException
from playwright.sync_api import sync_playwright
from app.schemas import IpatAuth
from app.services.parsers import parse_jra_csv
from app.services.supabase_client import get_supabase_client
from app.constants import RACE_COURSE_MAP

def _map_ticket_to_db_format(ticket_data, user_id):
    """ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’DBã®ticketsãƒ†ãƒ¼ãƒ–ãƒ«ã®å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    raw = ticket_data["raw"]
    parsed = ticket_data["parsed"]

    # race_id (YYYYMMDDPPRR) ã®ç”Ÿæˆ
    place_code = RACE_COURSE_MAP.get(raw["race_place"], "00")
    race_no = raw["race_number_str"].zfill(2)
    race_id = f"{raw['race_date_str']}{place_code}{race_no}"

    # receipt_unique_id (ãƒãƒƒã‚·ãƒ¥åŒ–) ã®ç”Ÿæˆ
    content_str = json.dumps(parsed["content"], sort_keys=True)
    # ã€ä¿®æ­£ã€‘æ—¥ä»˜ã‚’å«ã‚ã¦ã€æ—¥ã‚’ã¾ãŸã„ã§ã‚‚ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹
    unique_str = f"{raw['race_date_str']}-{raw['receipt_no']}-{raw['line_no']}-{content_str}"
    receipt_unique_id = hashlib.md5(unique_str.encode()).hexdigest()

    # total_points ã®è¨ˆç®— (0é™¤ç®—ã‚’å›é¿)
    total_points = 0
    if parsed["amount_per_point"] > 0:
        total_points = parsed["total_cost"] // parsed["amount_per_point"]

    # DBã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ§‹æˆ
    return {
        "user_id": user_id,
        "race_id": race_id,
        "bet_type": parsed["bet_type"],
        "buy_type": parsed["buy_type"],
        "content": parsed["content"],
        "amount_per_point": parsed["amount_per_point"],
        "total_points": total_points,
        "total_cost": parsed["total_cost"],
        "payout": parsed["payout"],
        "status": parsed["status"],
        "source": "IPAT_SYNC",
        "receipt_unique_id": receipt_unique_id
    }


def sync_and_save_past_history(log_id: str, user_id: str, creds: IpatAuth):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼"""
    supabase = get_supabase_client()
    print(f"BACKGROUND JOB STARTED for log_id: {log_id}")

    try:
        # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ãƒ‘ãƒ¼ã‚¹
        parsed_tickets = _scrape_past_history_csv(creds)
        if not parsed_tickets:
            # ãƒã‚±ãƒƒãƒˆãŒ0ä»¶ã§ã‚‚æ­£å¸¸çµ‚äº†ã¨ã™ã‚‹
            supabase.table("sync_logs").update({
                "status": "COMPLETED",
                "message": "åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚æŠ•ç¥¨å±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }).eq("id", log_id).execute()
            print(f"âœ… BACKGROUND JOB COMPLETED: No tickets found for log_id: {log_id}")
            return

        # 2. DBå½¢å¼ã¸ã®å¤‰æ›
        db_records = [_map_ticket_to_db_format(t, user_id) for t in parsed_tickets]
        
        # 3. DBã¸ä¿å­˜ (Upsert)
        print(f"   Upserting {len(db_records)} records to 'tickets' table...")
        supabase.table("tickets").upsert(db_records, on_conflict="receipt_unique_id").execute()

        # --- æˆåŠŸæ™‚ã®ãƒ­ã‚°æ›´æ–°ï¼ˆæ—¢å­˜ã® upsert ã®ç›´å¾Œã«ç½®ãæ›ãˆï¼‰ ---
        update_payload = {
            "status": "COMPLETED",
            "message": f"åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(db_records)} ä»¶ã®æŠ•ç¥¨å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
        }
        res = supabase.table("sync_logs").update(update_payload).eq("id", log_id).execute()

        # supabase-py ã®è¿”ã‚Šå€¤ã¯ dict-like (data, error) ãªã®ã§ä¸¡æ–¹ãƒã‚§ãƒƒã‚¯
        update_error = getattr(res, "error", None) if hasattr(res, "error") else res.get("error") if isinstance(res, dict) else None
        update_data = getattr(res, "data", None) if hasattr(res, "data") else res.get("data") if isinstance(res, dict) else None

        if update_error:
            print(f"âš ï¸ Failed to update sync_logs (error): {update_error}")
        else:
            # data ãŒç©ºãƒªã‚¹ãƒˆãªã‚‰å¯¾è±¡è¡ŒãŒç„¡ã‹ã£ãŸå¯èƒ½æ€§
            if not update_data:
                print("âš ï¸ sync_logs row not found for update. Attempting to insert a new log record.")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æŒ¿å…¥ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«é…æ…®ã—ã¦ ipat_auth ç­‰ã¯å«ã‚ãªã„ï¼‰
                insert_payload = {
                    "id": log_id,
                    "status": "COMPLETED",
                    "message": f"åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(db_records)} ä»¶ã®æŠ•ç¥¨å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
                }
                ins_res = supabase.table("sync_logs").insert(insert_payload).execute()
                ins_error = getattr(ins_res, "error", None) if hasattr(ins_res, "error") else ins_res.get("error") if isinstance(ins_res, dict) else None
                if ins_error:
                    print(f"âŒ Failed to insert sync_logs fallback record: {ins_error}")
                else:
                    print("âœ… Inserted fallback sync_logs record.")
            else:
                print("âœ… sync_logs updated successfully.")

        print(f"âœ… BACKGROUND JOB COMPLETED for log_id: {log_id}")

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç¿»è¨³
        error_str = str(e)
        user_friendly_error = error_str
        
        if "Login Failed: Invalid Credentials" in error_str:
            user_friendly_error = "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚åŠ å…¥è€…ç•ªå·ã€æš—è¨¼ç•ªå·ã€P-ARSç•ªå·ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        elif "Session timed out" in error_str:
            user_friendly_error = "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        elif "Login Failed or Menu Changed" in error_str:
            user_friendly_error = "ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ç”»é¢é·ç§»ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        
        error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {user_friendly_error}"
        
        print(f"âŒ BACKGROUND JOB FAILED for log_id: {log_id}. Error: {error_message}")
        try:
            res = supabase.table("sync_logs").update({
                "status": "ERROR",
                "message": error_message
            }).eq("id", log_id).execute()
            err = getattr(res, "error", None) if hasattr(res, "error") else res.get("error") if isinstance(res, dict) else None
            data = getattr(res, "data", None) if hasattr(res, "data") else res.get("data") if isinstance(res, dict) else None
            if err:
                print(f"âš ï¸ Failed to update sync_logs with ERROR status: {err}")
                # fallback insert
                try:
                    supabase.table("sync_logs").insert({
                        "id": log_id,
                        "status": "ERROR",
                        "message": error_message
                    }).execute()
                    print("âœ… Inserted fallback ERROR record into sync_logs.")
                except Exception as ins_e:
                    # æœ€çµ‚çš„ã«DBæ›´æ–°ã§ããªã‘ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ï¼ˆç›£æŸ»ç”¨ï¼‰
                    fname = f"failed_sync_log_{log_id}.log"
                    with open(fname, "w", encoding="utf-8") as f:
                        f.write(f"Failed to update/insert sync_logs for log_id={log_id}\nError: {error_message}\nDB error: {ins_e}\n")
                    print(f"âŒ Also failed to insert fallback sync_log; dumped info to {fname}")
            elif not data:
                print("âš ï¸ sync_logs update returned no data; row might not exist.")
        except Exception as db_error:
            print(f"  Additionally failed to update sync_logs: {db_error}")
            fname = f"failed_sync_log_{log_id}.log"
            with open(fname, "w", encoding="utf-8") as f:
                f.write(f"Additionally failed to update sync_logs for log_id={log_id}\nError: {db_error}\nOriginal error: {error_message}\n")
            print(f"âŒ Wrote debug log to {fname}")

def sync_and_save_recent_history(log_id: str, user_id: str, creds: IpatAuth):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ç›´è¿‘å±¥æ­´åŒæœŸã®å‡¦ç†ãƒ•ãƒ­ãƒ¼"""
    supabase = get_supabase_client()
    print(f"BACKGROUND JOB STARTED (RECENT) for log_id: {log_id}")

    try:
        # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨ãƒ‘ãƒ¼ã‚¹ (æœªå®Ÿè£…ã®ãŸã‚ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼)
        # parsed_tickets = _scrape_recent_history(creds)
        parsed_tickets = [] # ä»®
        
        print("â„¹ï¸ Recent history scraping is currently a placeholder.")

        if not parsed_tickets:
            # ãƒã‚±ãƒƒãƒˆãŒ0ä»¶ã§ã‚‚æ­£å¸¸çµ‚äº†ã¨ã™ã‚‹
            supabase.table("sync_logs").update({
                "status": "COMPLETED",
                "message": "åŒæœŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç›´è¿‘ã®æŠ•ç¥¨å±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }).eq("id", log_id).execute()
            print(f"âœ… BACKGROUND JOB COMPLETED: No tickets found for log_id: {log_id}")
            return

        # ä»¥ä¸‹ã€å®Ÿè£…æ™‚ã¯DBä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 

    except Exception as e:
        error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        print(f"âŒ BACKGROUND JOB FAILED for log_id: {log_id}. Error: {error_message}")
        try:
            supabase.table("sync_logs").update({
                "status": "ERROR",
                "message": error_message
            }).eq("id", log_id).execute()
        except Exception as db_error:
            print(f"  Additionally failed to update sync_logs: {db_error}")

def _scrape_past_history_csv(creds: IpatAuth):
    """Playwrightã«ã‚ˆã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¨CSVãƒ‘ãƒ¼ã‚¹å‡¦ç†ã‚’æ‹…ã† (æ—§sync_past_history)"""
    print("ğŸš€ Accessing JRA Vote Inquiry (PC/CSV Mode)...")
    all_parsed_data = []
    
    with sync_playwright() as p:
        is_headless = os.getenv("HEADLESS", "true").lower() != "false"
        browser = p.chromium.launch(headless=is_headless)
        # User-Agentã‚’è¨­å®šã—ã¦ã€ä¸€èˆ¬çš„ãªãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã«è¦‹ã›ã‹ã‘ã‚‹
        context = browser.new_context(
            accept_downloads=True,
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        context.route("**/*.{png,jpg,jpeg,gif,webp,svg,woff,woff2,css}", lambda route: route.abort())
        page = context.new_page()
        page.on("dialog", lambda dialog: dialog.accept())
        
        print("ğŸ‘‰ Logging in to PC site...")
        page.goto("https://www.nvinq.jra.go.jp/jra/")
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ä¿å­˜
        with open("debug_login_page.html", "w", encoding="utf-8") as f: f.write(page.content())

        # å…¥åŠ›å€¤ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå‰å¾Œã®ç©ºç™½å‰Šé™¤ï¼‰
        s_no = creds.subscriber_number.strip()
        pwd = creds.password.strip()
        pars = creds.pars_number.strip()

        page.wait_for_selector("#UID")
        page.locator("#UID").fill(s_no)
        page.wait_for_timeout(500)
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã«ã‚ˆã‚Šå…¥ã‚Œæ›¿ãˆ: æš—è¨¼ç•ªå·æ¬„ã«P-ARSã€P-ARSæ¬„ã«æš—è¨¼ç•ªå·ã‚’å…¥åŠ›
        page.locator("#PWD").fill(pars)
        page.wait_for_timeout(500)
        page.locator("#PARS").fill(pwd)
        page.wait_for_timeout(500)
        page.locator("input[type='submit'][value='ãƒ­ã‚°ã‚¤ãƒ³']").click()
        page.wait_for_load_state("networkidle")

        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯
        if page.locator("text=åŠ å…¥è€…ç•ªå·ãƒ»æš—è¨¼ç•ªå·ãƒ»P-ARSç•ªå·ã«èª¤ã‚ŠãŒã‚ã‚Šã¾ã™").is_visible():
             with open("debug_login_failed.html", "w", encoding="utf-8") as f: f.write(page.content())
             raise Exception("Login Failed: Invalid Credentials (åŠ å…¥è€…ç•ªå·ãƒ»æš—è¨¼ç•ªå·ãƒ»P-ARSç•ªå·ã«èª¤ã‚ŠãŒã‚ã‚Šã¾ã™)")

        print("ğŸ‘‰ Navigating to Vote Inquiry (JRAWeb320)...")
        menu_btn = page.locator("tr:has-text('æŠ•ç¥¨å†…å®¹ç…§ä¼š') input[type='submit']").first
        if not menu_btn.is_visible():
            menu_btn = page.locator("input[value='é¸æŠ']").first
        if not menu_btn.is_visible():
            with open("debug_login_failed.html", "w", encoding="utf-8") as f: f.write(page.content())
            raise Exception("Login Failed or Menu Changed. See debug_login_failed.html")
        menu_btn.click()
        page.wait_for_load_state("networkidle")

        print("ğŸ‘‰ Navigating to Receipt Number List (JRAWeb020)...")
        accept_link = page.locator("a.toAcceptnoNum")
        if accept_link.is_visible():
            accept_link.click()
        else:
            page.evaluate("document.forms['Go020'].submit()")
        
        # --- ã“ã“ã‹ã‚‰ä¿®æ­£ ---
        # ãƒšãƒ¼ã‚¸é·ç§»ã‚’å¾…æ©Ÿã—ã€ã¾ãšã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
        try:
            # ã€Œæ—¥ä»˜é¸æŠã€ãƒšãƒ¼ã‚¸ã€ã¾ãŸã¯ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œã€ãƒšãƒ¼ã‚¸ã®ã©ã¡ã‚‰ã‹ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
            page.wait_for_load_state("domcontentloaded", timeout=15000)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œç”»é¢ã®ç‰¹æœ‰ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã§åˆ¤å®š
            if page.locator("text=ãƒ­ã‚°ã‚¤ãƒ³ãŒç„¡åŠ¹ã¨ãªã£ãŸã‹").is_visible():
                raise Exception("Session timed out or became invalid. Please try again.")

        except Exception as e:
            # is_visible()ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„ã€ç‹¬è‡ªã«raiseã—ãŸä¾‹å¤–ã‚’æ•æ‰
            error_message = str(e) if str(e) else "Failed to determine page state after navigation."
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æœ€çµ‚çš„ãªç”»é¢ã‚’ä¿å­˜
            with open("debug_navigation_error.html", "w", encoding="utf-8") as f:
                f.write(page.content())
            raise Exception(error_message)

        print("ğŸ‘‰ Checking Date List...")
        date_buttons = page.locator("input[value='é¸æŠ']")
        date_count = date_buttons.count()
        print(f"ğŸ‘€ Found {date_count} date buttons.")

        if date_count == 0:
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã¯é€šéã—ãŸãŒãƒœã‚¿ãƒ³ãŒãªã„å ´åˆ
            print("âš ï¸ No dates found. Maybe no betting history.")
            return []
        # --- ã“ã“ã¾ã§ä¿®æ­£ ---

        for i in range(date_count):
            page.locator("input[value='é¸æŠ']").nth(i).click()
            page.wait_for_load_state("networkidle")
            csv_btn = page.locator("form[action*='JRACSVDownload'] input[name='normal']")
            if csv_btn.is_visible():
                with page.expect_download() as download_info:
                    csv_btn.click()
                download = download_info.value
                csv_path = f"temp_history_{i}.csv"
                download.save_as(csv_path)
                parsed = parse_jra_csv(csv_path)
                all_parsed_data.extend(parsed)
                os.remove(csv_path)
            
            back_btn = page.locator("input[value*='æ—¥ä»˜é¸æŠ']").first
            if back_btn.is_visible():
                back_btn.click()
            else:
                page.go_back()
            page.wait_for_load_state("networkidle")

        browser.close()

    return all_parsed_data