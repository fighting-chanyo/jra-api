from datetime import date, datetime, timedelta, timezone
import json
import time
from app.services.netkeiba_scraper import NetkeibaScraper
from app.services.supabase_client import get_supabase_client
from app.services.judgment_logic import JudgmentLogic
from app.schemas import Race, PayoutData, Ticket

class RaceService:
    def __init__(self):
        self.scraper = NetkeibaScraper()
        self.supabase = get_supabase_client()

    def import_schedule(self, year: int, month: int):
        """
        æŒ‡å®šå¹´æœˆã®ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–ã‚Šè¾¼ã¿ã€DBã«ä¿å­˜ã™ã‚‹
        """
        print(f"ğŸ“… Importing schedule for {year}-{month}...")
        try:
            races_data = self.scraper.scrape_monthly_schedule(year, month)
            print(f"DEBUG: Scraped {len(races_data)} races.")
            
            # DBã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦æ¯”è¼ƒã™ã‚‹ãŸã‚ã®æº–å‚™
            # æœˆã®ç¯„å›²ã‚’è¨ˆç®—
            start_date = date(year, month, 1)
            if month == 12:
                end_date = date(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = date(year, month + 1, 1) - timedelta(days=1)
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            # id, name, post_time, external_id ãŒã‚ã‚Œã°åˆ¤å®šå¯èƒ½
            existing_races_resp = self.supabase.table("races") \
                .select("id, name, post_time, external_id") \
                .gte("date", start_date.isoformat()) \
                .lte("date", end_date.isoformat()) \
                .execute()
            
            existing_races_map = {r['id']: r for r in existing_races_resp.data}
            
            db_records = []
            skipped_count = 0

            for r in races_data:
                # IDç”Ÿæˆ: YYYYMMDD + PlaceCode(2) + RaceNo(2)
                race_id = f"{r['date']}{r['place_code']}{str(r['race_number']).zfill(2)}"
                
                # dateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å¤‰æ›
                race_date = datetime.strptime(r['date'], "%Y%m%d").date()
                
                record = {
                    "id": race_id,
                    "date": race_date.isoformat(),
                    "place_code": r['place_code'],
                    "race_number": r['race_number'],
                    "name": r['name'],
                    "post_time": r['post_time'].isoformat() if r['post_time'] else None,
                    "external_id": r['external_id'],
                }

                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
                if race_id in existing_races_map:
                    existing = existing_races_map[race_id]
                    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå…¨ã¦åŸ‹ã¾ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    # id, date, place_code, race_number ã¯ not null ãªã®ã§ã€
                    # name, post_time, external_id ã‚’ãƒã‚§ãƒƒã‚¯
                    is_complete = (
                        existing.get('name') is not None and
                        existing.get('post_time') is not None and
                        existing.get('external_id') is not None
                    )
                    
                    if is_complete:
                        # æ—¢ã«å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—
                        skipped_count += 1
                        continue

                db_records.append(record)
            
            print(f"DEBUG: Skipped {skipped_count} complete records. Upserting {len(db_records)} records.")
            
            if db_records:
                # ãƒãƒƒãƒã§Upsert (50ä»¶ãšã¤åˆ†å‰²ã—ã¦é€ä¿¡)
                print(f"   Upserting {len(db_records)} races...")
                
                batch_size = 50
                for i in range(0, len(db_records), batch_size):
                    batch = db_records[i:i + batch_size]
                    try:
                        self.supabase.table("races").upsert(batch).execute()
                        print(f"   Upserted batch {i // batch_size + 1} ({len(batch)} records)")
                        time.sleep(1) # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿
                    except Exception as e:
                        print(f"ERROR upserting batch {i // batch_size + 1}: {e}")
            
            return len(db_records)
        except Exception as e:
            print(f"ERROR in import_schedule: {e}")
            import traceback
            traceback.print_exc()
            return 0

    def update_results(self, target_date: date = None):
        """
        æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹çµæœã‚’æ›´æ–°ã—ã€çš„ä¸­åˆ¤å®šã‚’è¡Œã†
        target_date: æŒ‡å®šãŒãªã„å ´åˆã¯å½“æ—¥(date.today())
        """
        target_date = target_date or date.today()
        
        print(f"ğŸ Updating results for {target_date}...")
        
        # 1. DBã‹ã‚‰å½“æ—¥ã®ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾— (status != 'FINISHED')
        # post_time ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯Pythonå´ã§è¡Œã†
        
        # Supabaseã‚¯ã‚¨ãƒª
        res = self.supabase.table("races").select("*").eq("date", target_date.isoformat()).neq("status", "FINISHED").execute()
        races = res.data
        
        if not races:
            print(f"   No pending races found for {target_date}.")
            return {"processed": 0, "hits": 0}

        processed_count = 0
        total_hits = 0
        
        # ç¾åœ¨æ™‚åˆ»ã‚’UTCã§å–å¾—
        now_utc = datetime.now(timezone.utc)

        for race in races:
            # ç™ºèµ°æ™‚åˆ»ãƒã‚§ãƒƒã‚¯
            if race.get("post_time"):
                try:
                    # ISOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
                    post_time = datetime.fromisoformat(race["post_time"])
                    
                    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã®æœ‰ç„¡ã‚’ç¢ºèªã—ã¦UTCã«çµ±ä¸€
                    if post_time.tzinfo is None:
                        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã€DBãŒUTCã§ä¿å­˜ã—ã¦ã„ã‚‹ã¨ä»®å®šã—ã¦UTCã‚’ä»˜ä¸
                        # ã‚‚ã—JSTã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãªã‚‰ timezone(timedelta(hours=9)) ã‚’ä»˜ä¸
                        # Supabaseã®timestamptzã¯é€šå¸¸UTCã§è¿”ã‚‹
                        post_time = post_time.replace(tzinfo=timezone.utc)
                    else:
                        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯UTCã«å¤‰æ›
                        post_time = post_time.astimezone(timezone.utc)
                    
                    # ç¾åœ¨æ™‚åˆ»ã¨æ¯”è¼ƒ (ç™ºèµ°æ™‚åˆ» > ç¾åœ¨æ™‚åˆ» ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—)
                    if post_time > now_utc:
                        print(f"   Skipping Race {race['id']}: Post time {post_time} is in the future (Now: {now_utc})")
                        continue
                        
                except ValueError as e:
                    print(f"   âš ï¸ Error parsing post_time for Race {race['id']}: {e}")
                    continue

            external_id = race.get("external_id")
            if not external_id:
                continue

            print(f"   Checking result for Race {race['id']} (Ext: {external_id})...")
            
            # 2. çµæœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
            result_data = self.scraper.scrape_race_result(external_id)
            if not result_data:
                print("      -> Not finalized yet.")
                continue

            print(f"DEBUG: Scraped result data for {race['id']}: {result_data}")

            # 3. DBæ›´æ–° (Races)
            update_payload = {
                "result_1st": result_data["result_1st"],
                "result_2nd": result_data["result_2nd"],
                "result_3rd": result_data["result_3rd"],
                "payout_data": result_data["payout_data"],
                "status": "FINISHED"
            }
            print(f"DEBUG: Updating race {race['id']} with payload: {update_payload}")
            
            try:
                self.supabase.table("races").update(update_payload).eq("id", race["id"]).execute()
                print(f"DEBUG: Successfully updated race {race['id']}")
            except Exception as e:
                print(f"ERROR updating race {race['id']}: {e}")

            processed_count += 1

            # 4. çš„ä¸­åˆ¤å®š
            hits = self._process_hit_detection(race["id"], result_data)
            total_hits += hits

        return {"processed": processed_count, "hits": total_hits}

    def _process_hit_detection(self, race_id: str, result_data: dict):
        """
        ç‰¹å®šã®ãƒ¬ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹ãƒã‚±ãƒƒãƒˆã®çš„ä¸­åˆ¤å®šã‚’è¡Œã†
        """
        # å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã®PENDINGãƒã‚±ãƒƒãƒˆã‚’å–å¾—
        res = self.supabase.table("tickets").select("*").eq("race_id", race_id).eq("status", "PENDING").execute()
        tickets = res.data
        
        if not tickets:
            return 0

        print(f"      Processing {len(tickets)} tickets for Race {race_id}...")
        
        hit_count = 0
        payout_data_obj = PayoutData(**result_data["payout_data"])
        
        # 1ç€ã€œ3ç€ã®é¦¬ç•ª (int)
        try:
            r1 = int(result_data["result_1st"])
            r2 = int(result_data["result_2nd"])
            r3 = int(result_data["result_3rd"])
        except (ValueError, TypeError):
            print("      âš ï¸ Error parsing result horse numbers.")
            return 0

        for t_dict in tickets:
            # Ticketãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
            ticket = Ticket(**t_dict)
            
            judged_status, payout = JudgmentLogic.judge_ticket(ticket, r1, r2, r3, payout_data_obj)
            
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä»•æ§˜ã«åˆã‚ã›ã¦ "HIT" ã‚’ "WIN" ã«å¤‰æ›´
            status_to_update = "WIN" if judged_status == "HIT" else judged_status
            
            if status_to_update == "WIN":
                hit_count += 1
                print(f"         ğŸ‰ WIN! Ticket {ticket.id}: {payout} yen")
            
            # ãƒã‚±ãƒƒãƒˆæ›´æ–°
            self.supabase.table("tickets").update({
                "status": status_to_update,
                "payout": payout
            }).eq("id", ticket.id).execute()
            
        return hit_count
